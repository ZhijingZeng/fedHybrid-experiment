{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload\n",
    "from tune_and_draw import TuneAndDraw\n",
    "from fedhybrid_innerloops import FedHybrid\n",
    "from parameter import TuneParam,TrainParam\n",
    "from costFunc import LogisticCostFunc\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from scipy.optimize import minimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saved_data(nclient):\n",
    "    with open('setup_3_result/train_data0'+str(nclient)+'.json', 'r') as fp: # data from xiaochun code\n",
    "        train_data = json.load(fp)\n",
    "\n",
    "        \n",
    "    df_train = pd.DataFrame.from_dict(train_data['user_data'])\n",
    "    df_train = df_train.T\n",
    "\n",
    "    A_train = df_train['x'].to_numpy()\n",
    "    y_train = df_train['y'].to_numpy()\n",
    "\n",
    "    for i in range(nclient):\n",
    "        A_train[i]= np.array(A_train[i])\n",
    "        y_train[i] = np.array(y_train[i])\n",
    "\n",
    "    return A_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "for each device k, we generate samples (Xk, Yk) according to the model y = argmax(softmax(W x + b)), \n",
    "x ∈R60, W ∈ R10×60, b ∈ R10. We model Wk ∼ N (uk, 1),\n",
    "bk ∼ N (uk, 1), uk ∼ N (0, α); xk ∼ N (vk, Σ), where the\n",
    "covariance matrix Σ is diagonal with Σj,j = j^−1.2.\n",
    "Each element in the mean vector vk is drawn from N (Bk, 1), Bk ∼N(0, β).\n",
    "Therefore, α controls how much local models differ from each other and β controls how much the local data\n",
    "at each device differs from that of other devices. \n",
    "We vary α, β to generate three heterogeneous distributed datasets,\n",
    "denoted Synthetic (α, β), as shown in Figure 2. We also\n",
    "generate one IID dataset by setting the same W, b on all\n",
    "devices and setting Xk to follow the same distribution. Our\n",
    "goal is to learn a global W and b.\n",
    "'''\n",
    "class SampleParam: \n",
    "    def __init__(self, mean, sigma):\n",
    "        self.mean = mean\n",
    "        self.sigma = sigma\n",
    "\n",
    "\n",
    "def softmax(z):\n",
    "    ex = np.exp(z)\n",
    "    sum_ex = np.sum(np.exp(z))\n",
    "    return ex/sum_ex       \n",
    "\n",
    "def dataset(nclient,n):    \n",
    "    nsample_param=SampleParam(4,2)\n",
    "    prior_param=SampleParam(0,0.5)\n",
    "    ndim=12\n",
    "    nclass=2\n",
    "    print('local datasizes')\n",
    "    np.random.seed(2022)\n",
    "    random.seed(2022)\n",
    "    \n",
    "    #ni = np.random.lognormal(nsample_param.mean, nsample_param.sigma, nclient).astype(int) + 50 # number of samples per client\n",
    "    if nclient == 8 and n == 354:\n",
    "        ni=[45, 38, 29, 12, 62, 76, 36, 56]\n",
    "    else:\n",
    "        p = np.zeros(nclient)\n",
    "        s = 0\n",
    "        for i in range(nclient):\n",
    "            p[i] = random.uniform(0.1, 1)\n",
    "            s += p[i]\n",
    "        p = p/s\n",
    "        print(p)\n",
    "        ni = p * n\n",
    "        ni = [int(num) for num in ni]\n",
    "        ni[-1] = ni[-1] + n - sum(ni)\n",
    "     \n",
    "    \n",
    "    \n",
    "    A0 = [[] for _ in range(nclient)]\n",
    "    y0 = [[] for _ in range(nclient)]\n",
    "        #### define some eprior ####\n",
    "\n",
    "    mean_W = np.random.normal(prior_param.mean, prior_param.sigma, nclient)\n",
    "    print(prior_param.sigma)\n",
    "    mean_b = mean_W\n",
    "    mean_x = np.random.normal(prior_param.mean, prior_param.sigma, nclient)\n",
    "    mean_x = np.zeros((nclient, ndim))\n",
    "    for i in range(nclient):\n",
    "        mean_x[i] = np.random.normal(mean_x[i], 1, ndim)\n",
    "    diagonal = np.zeros(ndim)\n",
    "    for j in range(ndim):\n",
    "        diagonal[j] = np.power((j+1), -1.2)\n",
    "    cov_x = np.diag(diagonal)\n",
    "    for i in range(nclient):\n",
    "        W = np.random.normal(mean_W[i], 1, (ndim, nclass))\n",
    "        b = np.random.normal(mean_b[i], 1,  nclass)\n",
    "        Ai = np.random.multivariate_normal(mean_x[i], cov_x, ni[i])\n",
    "        yi = np.zeros(ni[i])\n",
    "        for j in range(ni[i]):\n",
    "            tmp = np.dot(Ai[j], W) + b\n",
    "            yi[j] = np.argmax(softmax(tmp))\n",
    "        A0[i] = Ai.tolist()\n",
    "        y0[i] = yi.tolist()\n",
    "#print('dsfadf',y0[5])\n",
    "    train_data = {'users': [], 'user_data':{}, 'num_samples':[]}\n",
    "\n",
    "    for i in range(nclient):\n",
    "        uname = 'f_{0:05d}'.format(i)        \n",
    "        combined = list(zip(A0[i], y0[i]))\n",
    "        random.shuffle(combined)\n",
    "        A0[i][:], y0[i][:] = zip(*combined) # The * operator can be used in conjunction with zip() to unzip the list.\n",
    "        num_samples = len(A0[i])\n",
    "        train_data['users'].append(uname) \n",
    "        train_data['user_data'][uname] = {'x': A0[i], 'y': y0[i]}\n",
    "        train_data['num_samples'].append(num_samples)\n",
    "        with open('setup_3_result/train_data0'+str(nclient)+'_'+str(n)+'.json', 'w') as fp:\n",
    "            json.dump(train_data, fp)\n",
    "        print(num_samples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare(nclient):\n",
    "\n",
    "    #dataset(nclient,n)\n",
    "    A, y =saved_data(nclient)\n",
    "    gamma = 1\n",
    "    func = LogisticCostFunc(A, y, gamma)\n",
    "    initial_x =np.array( [[0.99846005],\n",
    "    [0.14017568],\n",
    "    [0.43901654],\n",
    "    [0.71784581],\n",
    "    [0.83952553],\n",
    "    [0.00799748],\n",
    "    [0.7440322 ],\n",
    "    [0.78949782],\n",
    "    [0.12399082],\n",
    "    [0.85932448],\n",
    "    [0.21513528],\n",
    "    [0.91062862]])\n",
    "    fn_min = minimize(func.global_func, initial_x, tol=1e-30) #result object\n",
    "    fn_star = fn_min.fun\n",
    "    method = FedHybrid(func, fn_star)\n",
    "#ns=[0,2,4,6,8]\n",
    "#innerIterations = 3\n",
    "    tuneAndDraw = TuneAndDraw(nclient, initial_x,setup=3)\n",
    "    return method,tuneAndDraw\n",
    "#tuneAndDraw.draw(method,ns,innerIterations,method.train_innerloop_lambdaBefore)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "node 8, n = 354, synchronous synthetic logistic regreesion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "method,tuneAndDraw = prepare(8)\n",
    "ns=[0,2,4,6,8]\n",
    "innerIterations = 1\n",
    "df = tuneAndDraw.readPa(ns,innerIterations)\n",
    "filename=\"./sync_and_async/3 synchronous synthetic logistic regreesion before.pdf\"\n",
    "tuneAndDraw.draw(df,method.train_innerloop_lambdaBefore,\"synchronous synthetic logistic regreesion\",filename,save = 0,asyn=0,possionBeta=[])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "async"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "method,tuneAndDraw = prepare(8)\n",
    "ns=[0,2,4,6,8]\n",
    "innerIterations = 0 #only to point to a set of stepsizes with no real meaning\n",
    "df = tuneAndDraw.readPa(ns,innerIterations)\n",
    "filename=\"./analyze data/analyze data/sync_and_async/3 asynchronous synthetic logistic regreesion.pdf\"\n",
    "tuneAndDraw.draw(df,method.asynchronousTrain2,\"node 8 async synthetic logistic regreesion possionBeta=[4, 5, 10, 4, 2, 1, 2, 7, 100, 5]\",filename,save=0,asyn=1,possionBeta = [4, 5, 10, 1, 2, 7,100,5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with innerloops 4:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "method,tuneAndDraw = prepare(8)\n",
    "ns=[0,2,4,6,8]\n",
    "innerIterations = 4\n",
    "df = tuneAndDraw.readPa(ns,innerIterations)\n",
    "filename=\"./sync_and_async/3 innerloop 4 synthetic logistic regreesion before2.pdf\"\n",
    "tuneAndDraw.draw(df,method.train_innerloop_lambdaBefore,\"synthetic logistic regreesion innerloop 4\",filename,save =0,asyn=0,possionBeta=[])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('cs349hw2')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "83c011b6d1fd8ab47b12eb316f3cd78cbb02a3d22bfe1a70b86554592d45d8b7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
